#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
News Monitor â€“ ë³¸ë¬¸ ì¶”ì¶œ + LLM(JSON) íŒë‹¨ + í‚¤ì›Œë“œ ë³´ì¡° + ì£¼ë§ ìŠ¤í‚µ
- ì‹œíŠ¸ ê·œì¹™ìœ¼ë¡œ 1ì°¨ í•„í„°
- trafilatura ë³¸ë¬¸ ì¶”ì¶œ â†’ LLMì´ ì¡°ì§ ê´€ì  ì˜í–¥(ê¸ì •/ì¤‘ë¦½/ëª¨ë‹ˆí„°/ë¶€ì •)ì„ JSONìœ¼ë¡œ íŒì •
- í‚¤ì›Œë“œëŠ” íŒíŠ¸/ë³´ì¡° ìš©ë„ë¡œë§Œ ì‚¬ìš© (ê³¼ë„í•œ override ì œê±°)
- ë™ì¼ ì œëª©(ì •ê·œí™”) ì¤‘ë³µ ì œê±°
"""

from __future__ import annotations
import os, re, html, time, json, logging, requests, pandas as pd
from io import StringIO
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, timezone
from dateutil import parser as dtparser
from zoneinfo import ZoneInfo
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError  # noqa: F401
import tldextract, trafilatura

try:
    import openai  # pip install openai>=1.40.0
    _HAS_OPENAI = True
except Exception:
    _HAS_OPENAI = False

KST = ZoneInfo("Asia/Seoul")

# -------------------------
# ê³µí†µ ìœ í‹¸
# -------------------------
def now_kst(): return datetime.now(tz=KST)

def parse_datetime(dt_str: str | None):
    if not dt_str: return None
    try:
        dt = dtparser.parse(dt_str)
        if dt.tzinfo is None: dt = dt.replace(tzinfo=timezone.utc)
        return dt.astimezone(timezone.utc)
    except Exception: return None

def to_kst_str(dt): return "" if not dt else dt.astimezone(KST).strftime("%Y-%m-%d %H:%M")

def strip_html(text: str | None): return BeautifulSoup(html.unescape(text or ""), "html.parser").get_text(" ", strip=True)

def domain_from_url(url: str | None):
    if not url: return ""
    try:
        ext = tldextract.extract(url)
        return ".".join(p for p in [ext.domain, ext.suffix] if p)
    except Exception: return ""

def norm_title(t: str | None):
    t = strip_html(t or "").lower()
    t = re.sub(r"[\[\]()<>ã€ã€ã€Œã€]", " ", t)
    t = re.sub(r"[^\wê°€-í£\s]", " ", t)
    return re.sub(r"\s+", " ", t).strip()

# -------------------------
# ì¡°íšŒ êµ¬ê°„
# -------------------------
def compute_window_utc(now=None):
    now = now or now_kst()
    anchor = now.astimezone(KST).replace(hour=9, minute=0, second=0, microsecond=0)
    days = 3 if anchor.weekday() == 0 else 1
    return (anchor - timedelta(days=days)).astimezone(timezone.utc), anchor.astimezone(timezone.utc)

# -------------------------
# ì‹œíŠ¸ ë¡œë”
# -------------------------
def _split_list(val): return [] if pd.isna(val) or not str(val).strip() else [x.strip().lower() for x in str(val).split(",") if x.strip()]

def _query_tokens_from(q): 
    if not q: return []
    return [p.strip().strip('"').strip("'").lower() for p in re.split(r'\bOR\b', q, flags=re.I) if p.strip()]

def fetch_org_list():
    sheet_url = os.environ.get("SHEET_CSV_URL", "").strip()
    if not sheet_url: raise RuntimeError("SHEET_CSV_URL not set.")
    df = pd.read_csv(StringIO(requests.get(sheet_url, timeout=30).content.decode("utf-8", "replace")))
    name_col = next((c for c in ["ì¡°ì§ëª…","í‘œì‹œëª…"] if c in df.columns), None)
    if not name_col: raise RuntimeError("CSVì— 'ì¡°ì§ëª…' ë˜ëŠ” 'í‘œì‹œëª…' í•„ìš”")
    rows=[]; seen=set()
    for _,r in df.iterrows():
        display=str(r[name_col]).strip()
        if not display or display.lower()=="nan": continue
        item={
            "display":display,"query":str(r.get("ê²€ìƒ‰ì–´","")).strip() or display,
            "kind":str(r.get("ìœ í˜•","ORG")).strip().upper() or "ORG",
            "must_all":_split_list(r.get("MUST_ALL","")),
            "must_any":_split_list(r.get("MUST_ANY","")),
            "block":_split_list(r.get("BLOCK","")),
        }
        item["query_tokens"]=_query_tokens_from(item["query"])
        key=(item["display"],item["query"])
        if key not in seen: rows.append(item); seen.add(key)
    return rows

# -------------------------
# ë³¸ë¬¸ ì¶”ì¶œ
# -------------------------
def fetch_article_text(url, timeout=20):
    if not url: return ""
    try:
        d = trafilatura.fetch_url(url, no_ssl=True, timeout=timeout)
        if d: return (trafilatura.extract(d, favor_recall=True, deduplicate=True) or "").strip()
    except Exception: pass
    try: return strip_html(requests.get(url,timeout=timeout,headers={"User-Agent":"Mozilla/5.0"}).text)[:8000].strip()
    except Exception: return ""

# -------------------------
# ë‰´ìŠ¤ ê²€ìƒ‰ê¸°
# -------------------------
def search_naver(query, display=20):
    cid,csec=os.environ.get("NAVER_CLIENT_ID",""),os.environ.get("NAVER_CLIENT_SECRET","")
    if not cid or not csec: return []
    try:
        r=requests.get("https://openapi.naver.com/v1/search/news.json",
            headers={"X-Naver-Client-Id":cid,"X-Naver-Client-Secret":csec},
            params={"query":query,"display":display,"start":1,"sort":"date"},timeout=20).json()
        return [{"title":strip_html(it.get("title")),"url":it.get("originallink") or it.get("link"),
                 "source":domain_from_url(it.get("originallink") or it.get("link")) or "naver",
                 "published_at":parse_datetime(it.get("pubDate")),"origin":"naver",
                 "summary":strip_html(it.get("description",""))}
                for it in r.get("items",[]) if it.get("title")]
    except Exception: return []

def search_newsapi(query, f,t,language="ko"):
    key=os.environ.get("NEWSAPI_KEY","")
    if not key: return []
    try:
        r=requests.get("https://newsapi.org/v2/everything",
            params={"q":query,"from":f.isoformat().replace("+00:00","Z"),
                    "to":t.isoformat().replace("+00:00","Z"),
                    "sortBy":"publishedAt","pageSize":50,"language":language,"apiKey":key},timeout=20).json()
        return [{"title":strip_html(a.get("title")),"url":a.get("url"),
                 "source":(a.get("source") or {}).get("name") or domain_from_url(a.get("url")),
                 "published_at":parse_datetime(a.get("publishedAt")),"origin":"newsapi",
                 "summary":strip_html(a.get("description") or a.get("content") or "")}
                for a in r.get("articles",[]) if a.get("title")]
    except Exception: return []

# -------------------------
# í‚¤ì›Œë“œ ì„¸íŠ¸ (ì •ë¹„ëœ ë²„ì „)
# -------------------------
STRONG_NEG=[
  "íš¡ë ¹","ë°°ì„","ì‚¬ê¸°","ê³ ë°œ","ê¸°ì†Œ","êµ¬ì†","ìˆ˜ì‚¬","ì••ìˆ˜ìˆ˜ìƒ‰","ì†Œì†¡","ê³ ì†Œ","ë¶„ìŸ",
  "ë¦¬ì½œ","ê²°í•¨","ì§•ê³„","ì œì¬","ë²Œê¸ˆ","ê³¼ì§•ê¸ˆ","ë¶€ì‹¤","íŒŒì‚°","ë¶€ë„","ì˜¤ì—¼","ì‚¬ë§","ë¶€ìƒ",
  "í­ë°œ","í™”ì¬","ì¶”ë½","ìœ ì¶œ","í•´í‚¹","ëœì„¬ì›¨ì–´","ì¹¨í•´","ì•…ì„±ì½”ë“œ","ë‹´í•©","ë…ì ","ë¶ˆë§¤",
  "ë…¼ë€","ê°‘ì§ˆ","í‘œì ˆ","í˜ì˜","ë¶ˆë²•","ìœ„ë²•","ì·¨ì†Œ","ì² íšŒ","ë¶€ì •","ì ì","ê¸‰ë½","í•˜ë½","ì§•ì—­"
]
POS_KW=["ìˆ˜ìƒ","ì„ ì •","í›„ì›","ì§€ì›","ê¸°ë¶€","íˆ¬ì","íŒŒíŠ¸ë„ˆì‹­","mou","ê³„ì•½","ìˆ˜ì£¼","ì¸ì¦","ìŠ¹ì¸"]

def calc_risk_signals(title, summary, content):
    text=f"{title} {summary} {content}".lower()
    strong=[kw for kw in STRONG_NEG if kw.lower() in text]
    pos=[kw for kw in POS_KW if kw.lower() in text]
    return {"score":len(strong)*2-len(pos),"strong_neg":strong,"hints_text":("ë¶€ì •:"+",".join(strong)) if strong else ""}

# -------------------------
# LLM ë¼ë²¨ëŸ¬
# -------------------------
IMPACT_MAP={"positive":"ğŸ”µ","neutral":"ğŸŸ¢","monitor":"ğŸŸ¡","negative":"ğŸ”´"}

def llm_enabled(): 
    return os.environ.get("LLM_ENABLE","").lower() in {"1","true","yes"} and os.environ.get("OPENAI_API_KEY") and _HAS_OPENAI

def llm_label(display,title,summary,content,hints):
    if not llm_enabled(): return None
    body=(content or "").strip()[:3500]
    strong_info = f"ê°•í•œ ë¶€ì • í‚¤ì›Œë“œ ê°ì§€: {hints}" if hints else "ì—†ìŒ"
    prompt=f"""ë‹¹ì‹ ì€ ìœ„ê¸°ê´€ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê¸°ì‚¬ê°€ '{display}'ì— ì£¼ëŠ” ì˜í–¥ì„ í‰ê°€í•˜ì„¸ìš”.
- ë¶„ë¥˜: positive(ê¸ì •), neutral(ì¤‘ë¦½), monitor(ëª¨ë‹ˆí„°ë§ í•„ìš”), negative(ë¶€ì •)
- ê¸ì • ì‹ í˜¸(ìˆ˜ìƒ/ì„ ì •/í›„ì›/ì§€ì›/ê¸°ë¶€/íˆ¬ì/íŒŒíŠ¸ë„ˆì‹­ ë“±)ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê¸ì •ì .
- ê°•í•œ ë¶€ì • í‚¤ì›Œë“œê°€ ê¸°ì‚¬ì— í¬í•¨ë˜ë”ë¼ë„, '{display}'ì™€ ì§ì ‘ì  ê´€ë ¨ì´ ì—†ë‹¤ë©´ ë¶€ì •ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ˆì„¸ìš”.
- ì• ë§¤í•˜ë©´ monitorë¡œ ë¶„ë¥˜í•˜ë˜, ê³¼ë„í•˜ê²Œ ë³´ìˆ˜ì ì¼ í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.

JSON ì˜ˆì‹œ:
{{"impact":"positive|neutral|monitor|negative","confidence":0.0-1.0,"evidence":["ê·¼ê±°1","ê·¼ê±°2"]}}

[ì œëª©]{title}
[ìš”ì•½]{summary}
[ë³¸ë¬¸]{body}
[ë¶€ì • í‚¤ì›Œë“œ]{strong_info}"""
    try:
        resp=openai.OpenAI(api_key=os.environ["OPENAI_API_KEY"]).chat.completions.create(
            model=os.environ.get("LLM_MODEL","gpt-4o-mini"),
            messages=[{"role":"user","content":prompt}],temperature=0,max_tokens=220)
        raw=(resp.choices[0].message.content or "").strip()
        data=json.loads(raw)
        return {"label":IMPACT_MAP.get(data.get("impact",""),None),"confidence":float(data.get("confidence",0.5)),"raw":data}
    except Exception: return None

# -------------------------
# Slack
# -------------------------
def post_to_slack(lines):
    token,channel=os.environ.get("SLACK_BOT_TOKEN",""),os.environ.get("SLACK_CHANNEL","")
    if not token or not channel: raise RuntimeError("Slack token/channel missing.")
    WebClient(token=token).chat_postMessage(channel=channel,text="\n".join(lines) if lines else "ì˜¤ëŠ˜ì€ ì‹ ê·œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------
# main
# -------------------------
def main():
    logging.basicConfig(level=logging.INFO,format="%(asctime)s %(levelname)s %(message)s")
    if now_kst().weekday() in (5,6): return
    f,t=compute_window_utc(); rows=fetch_org_list(); all_lines=[]
    for row in rows:
        items=search_naver(row["query"],20)+search_newsapi(row["query"],f,t)
        uniq={}; 
        for it in items:
            key=norm_title(it["title"])
            if key and it.get("published_at") and f<=it["published_at"]<t: uniq[key]=it|{"display":row["display"],"row_cfg":row}
        for art in uniq.values():
            content=fetch_article_text(art["url"])
            signals=calc_risk_signals(art["title"],art.get("summary",""),content)
            out=llm_label(art["display"],art["title"],art.get("summary",""),content,signals["hints_text"])
            if out: label,conf=out["label"],out["confidence"]
            else: label,conf="ğŸŸ¢",0.5
            # ë³´ì •: í™•ì‹  ë§¤ìš° ë‚®ê³ (score ë†’ìŒ) â†’ monitor
            if label in {"ğŸ”µ","ğŸŸ¢"} and conf<0.4 and signals["score"]>=5: label="ğŸŸ¡"
            all_lines.append(f"[{art['display']}] <{art['url']}|{art['title']}> ({art['source']})({to_kst_str(art['published_at'])}) [{label}]")
    post_to_slack(all_lines)

if __name__=="__main__":
    main()
